---
format: 
   revealjs:
      theme: ["../theme/q-theme.scss"]
      slide-number: c/t
      logo: POPUHEALSMPH_color-flush.png
      code-copy: true
      center-title-slide: false
      code-link: true
      code-overflow: wrap
      highlight-style: a11y
      height: 1080
      width: 1920
      chalkboard: true
execute: 
   eval: true
   echo: true
---


<h1> PHS 651: Advanced regression methods </h1>

<h2> Lecture 0: Introduction </h2>

<hr>

<h3> Mary Ryan, PhD </h3>

<h3> September 5, 2024 </h3>

---

## How this is different

- What you covered in PHS 552
   - What is regression
   - How to build a mean model
   - Models for different types of outcomes (normal, logistic, Poisson, etc)
   - What happens when constant variance breaks?

. . .

- What we'll focus on here:
   - Same foundations, different style: what happens when observations [are not]{.alert} independent
      <!-- - Clustered data -->
      <!-- - Longitudinal/repeated measures data -->
      <!-- - Time-to-event/survival data -->

---

## Our focus

- We've previously assumed all observations are [independent]{.alert}
   - Can be a reasonable assumption in certain settings (certain cross-sectional studies)
   - When not reasonable, methods from PHS 552 can still be useful if other tools aren't available
      - We'll explore the boundaries of this
   
- Here, we'll be [expanding our statistical toolbox]{.alert}
   - Allows us to be [more precise]{.alert} when independence isn't reasonable
   - Lets us ask a [wider variety]{.alert} of questions

. . .

- When might independence not be reasonable?
   - Group membership makes in-group outcome variability different from between-group variability
      - i.e., health outcomes correlated by neighborhood, occular outcomes correlated by individual
   - We're observing the same individuals repeatedly (longitudinal data)

. . .

- Non-independence we [won't]{.alert} be getting into
   - Time series modeling
   - Spatial statistical modeling
   
---

## Examples!

---

## Outline

- Review of generalized linear models, weighted least squares
- Cross-sectional clustered data
- Conditional modeling: linear mixed effect models (LMEs), generalized linear mixed models (GLMMs)
- Marginal modeling : generalized estimationg equations (GEEs)
- Modeling repeated measures: multi-period cross-sectional data, longitudinal data
- Multilevel modeling
- Longitudinal smoothing
- Time-to-event/survival analysis

---

## What I'm assuming you're coming in with

- Familiarity with basic statistical inference concepts (i.e., estimation, hypothesis testing, confidence intervals)
- Basic regression/ANOVA
- (Generally) how to build a mean model (i.e., confounding and precision variables)
- Familiarity with matrix notation
   - Do NOT need to know advanced linear algebra/calculus
   - Should be familiar with matrix addition/subtraction/multiplication/inversion
   - Won't make you do the nitty gritty but will help you understand how some concepts work
   - We'll review and I'll post resources
- Basic SAS coding knowledge
   - I'll use SAS in teaching, but I also know how to do all of this in R
   - You can use whatever software you want for your assignments, just know there are softwares I may be less good at providing support in
   
---

## Review: ordinary linear regression
::: {columns}

::: {.column width="45%"}
$$Y_i = \beta_0 + \beta_1 X_i + \epsilon_i$$

- $Y_i$: outcome/dependent variable for individual $i$
- $X_i$: treatment/exposure/independent variable for individual $i$
- $\beta_0$: model intercept
   - Interpretation:
   <br>
   <br>
   <br>
   <br>
- $\beta_1$: model slope
   - Interpretation:
   <br>
   <br>
   <br>
   <br>
   
- $\epsilon_i$: error term

:::

::: {.column width="45%"}
<br>
What do I mean by the [mean model]{.alert}?
$$E[Y_i] = \beta_0 + \beta_1 X_i$$ 
:::

:::