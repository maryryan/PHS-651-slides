---
format: 
   revealjs:
      theme: ["../theme/q-theme.scss"]
      slide-number: c/t
      logo: POPUHEALSMPH_color-flush.png
      code-copy: true
      center-title-slide: false
      code-link: true
      code-overflow: wrap
      highlight-style: a11y
      height: 1080
      width: 1920
      chalkboard: true
      from: markdown+emoji
      fragment: true
      auto-stretch: false
execute: 
   eval: true
   echo: true
editor: 
  markdown: 
    wrap: 72
---

```{r load libraries, echo=F}
library(tidyverse)
library(ggdag)
library(dagitty)
library(gridExtra)
library(qrcode)
```

<h1>Lecture 5.2: Diagnostics & corrections</h1>

<h2>PHS 651: Advanced regression methods</h2>

<hr>

<h3>Mary Ryan Baumann, PhD</h3>

<h3>October 8, 2024</h3>

<br>

::: {style="font-size: 75%;"}
**Recording disclosure**

*This class is being conducted in person, as well as over [Zoom]{.alert}. As the instructor, I will be [recording]{.alert} this session. I have disabled the recording feature for others so that no one else will be able to record this session. I will be posting this session to the course’s website.*

*If you have privacy concerns and do not wish to appear in the recording, you may turn video off (click “stop video”) so that Zoom does not record you.*

*The chat box is always open for discussion and questions to the entire class. You may also send messages privately to the instructor. Please note that Zoom saves all chat transcripts.*
:::

::: {.absolute bottom=5 left=260 width=1500}

Slides found at: <https://maryryan.github.io/PHS-651-slides/PHS-651-5/slides-5>

:::

::: {.absolute bottom=0 left=100 width=150}
```{r qr code, echo=F, fig.height=2, fig.width=2}
plot(qr_code("https://maryryan.github.io/PHS-651-slides/PHS-651-5/slides-5"))
```
:::

---

## Model diagnostics

So far we've dealt with how to model correlated data

- But how do we assess whether the modeling choices we've made are sound?

. . .

There are some analyses/diagnostics we can perform to explore this

. . .

- Heavy emphasis on [explore]{.alert}

   - We know that our model likely won't perfectly reflect the true form/relationships in the data
   
   - But we should assess whether there are [major discrepancies]{.alert} between what we've assumed and what's in the data
   
   - Use these as a temperature check for whether the model needs to be adjusted, how much confidence can be placed in estimates, and whether estimates need to be presented with caveats

. . .

Also, in the non-longitudinal clustered data settings, there are not many diagnostic checks for GEE models

- This is because we aren't *assuming* much for GEEs - we're estimating most of the covariance matrix

- So we'll mostly be focusing on mixed models in this session

---

## Residual analysis

[Residuals]{.alert} are the difference between the observed outcomes and the ones predicted by your model

$$r_{ij} = Y_{ij} - \boldsymbol{X}_{ij}\widehat{\vec{\beta}}$$

. . .

If the model [adequately captures]{.alert} the systematic trend of the response, then [the residuals should exhibit no systematic pattern]{.alert}

- i.e., they should be scattered fairly randomly around zero

---

## Residuals vs predicted response

Residuals can be used to check for systematic departures from the model for the mean response

- We often do this by making a scatter plot of residuals vs predicted values

   - Fitting a smoothed curve (e.g., lowess) through the scatter plot is helpful in this respect
   
. . .

![](residual-plot-example.png){width=1000}

---

## Residuals vs predicted response
   
In OLS, any systematic pattern in the residual indicates inadequacy of the model

- Solution: re-fit the data with a more flexible model (e.g., interactions, quadratic terms, and perhaps more covariates)

![](residual-plot-example.png){width=1000}

---

## Residuals vs predicted response

But with correlated data, [errors from the same cluster are correlated]{.alert}, and don't necessarily have the same variance

- This means that homoscedasticity may not hold for residuals vs predicted response

   - i.e., "fanning" of residuals may not be a bad sign
   
![](residual-plot-example.png){width=1000}
   
---

## De-correlated residuals

One way to fix this is to "de-correlate" the residuals

- Done by transforming the residuals via [Cholesky decomposition]{.alert}

- This makes it so the components of the transformed residuals for cluster $i$ ($r^*_i$) are uncorrelated and have variance 1

---

## Cholesky decomposition

Given an estimate of the residual covariance matrix for cluster $i$, $\widehat{\Sigma}_i$, the Cholesky decomposition of this is
$$\widehat{\Sigma}_i = L_i L_i^T$$

- $L_i$ is a lower triangular matrix

The transformed residuals are then:
$$r^*_i = L_i^{-1}r_i$$

We would then plot the Cholesky-transformed residuals agains the Cholesky-transformed predicted response

---  

## Cholesky decomposition: Minnesota radon

Let's try this for our radon LME model
$$Y_{ij} = \beta_0 + \beta_1 (\text{floor}_{ij}) + b_{0i} + \epsilon_{ij}$$
```{r radon cleaning, echo=F}
radon <- read.table("~/Desktop/teaching/PHS-651/data/Gelman-data/radon/srrs2.dat",header=T,sep=",")

set.seed(081524)

radon.mn <- radon %>% 
   as.data.frame() %>% 
   mutate(log_radon = log(activity +0.1),
          county = str_trim(county)) %>% 
   dplyr::filter(state == "MN")
```


```{r radon nlme}
library(nlme)
library(mgcv)

# run an LME with random intercepts for county #
radon_nlme <- lme( log_radon ~ floor,
                   random = ~ 1 | county, data=radon.mn )

# get the residuals #
raw.residuals <- residuals(radon_nlme, level=0)

# Cholesky residuals
est.cov <- extract.lme.cov(radon_nlme, radon) # We extract the blocked covariance function of the residuals
Li <- t(chol(est.cov)) # We find the Cholesky transformation of the residuals. (The transform is to get the lower trangular matrix.)
cholesky.residuals <- solve(Li) %*% raw.residuals # We then calculate the transformed residuals.

hist(cholesky.residuals) # We plot the residuals

cholesky.fitted <- solve(Li) %*% fitted( radon_nlme)

plot(cholesky.fitted, cholesky.residuals)
```

---

## Cholesky decomposition

Unfortunately it's not easy to do this for GLMMs with non-Normal outcomes

---

## De-correlated residual vs covariate

Similar scatter plots of the de-correlated residuals against a particular covariate can be examined for systematic trend

- Such a trend may indicate omission of a quadratic term or need for transformation of the covariate

. . .

![](residual-covariate-plot.png){width=2000}

---

## Diagnostics for GEEs

While we don't do a lot of model testing for GEEs, we can compare the empirical estimates of the covariance structure to the model-based estimates

- If there is a large discrepancy, our robust variance estimator is probably doing the heavy lifting of correcting this for us

- In this setting (non-longitudinal clustered data) though, we aren't likely to see much discrepancy

---

## Small n corrections

Where we can focus on GEE is in the variance corrections department

- The sandwich variance estimator can help us out with misspecification, but it doesn't perform well when we don't have many (<50) clusters

   - Since sandwich estimators are more often used with GEEs and GLMMs, this "small n" issue is usually more common in GEE analyses

- There are several choices of correction you can implement in either SAS or R:

   - Mancl & DeRoun
   
   - Kauermann & Carroll
   
   - Fay & Graubard

- Which one you pick isn't so important (comparative benefits of each are relatively small)

- R: `geesmv` package: https://cran.r-project.org/web/packages/geesmv/geesmv.pdf

   - has all the regular corrections (KC, MR, FG)

- SAS: GLIMMIX has KC (EMPIRICAL=HC2), FG (EMPIRICAL=FIROEEQ), MR (EMPIRICAL=HC3)

   - nothing for GENMOND

---

## Informative cluster size