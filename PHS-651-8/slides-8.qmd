---
format: 
   revealjs:
      theme: ["../theme/q-theme.scss"]
      slide-number: c/t
      logo: POPUHEALSMPH_color-flush.png
      code-copy: true
      center-title-slide: false
      code-link: true
      code-overflow: wrap
      highlight-style: a11y
      height: 1080
      width: 1920
      chalkboard: true
      from: markdown+emoji
      fragment: true
      auto-stretch: false
execute: 
   eval: true
   echo: true
editor: 
  markdown: 
    wrap: 72
---

```{r load libraries, echo=F}
library(tidyverse)
library(ggdag)
library(dagitty)
library(gridExtra)
library(qrcode)
```

<h1>Lecture 8: Longitudinal GEEs & GLMMs</h1>

<h2>PHS 651: Advanced regression methods</h2>

<hr>

<h3>Mary Ryan Baumann, PhD</h3>

<h3>October 29, 2024</h3>

<br>

::: {style="font-size: 75%;"}
**Recording disclosure**

*This class is being conducted in person, as well as over [Zoom]{.alert}. As the instructor, I will be [recording]{.alert} this session. I have disabled the recording feature for others so that no one else will be able to record this session. I will be posting this session to the course’s website.*

*If you have privacy concerns and do not wish to appear in the recording, you may turn video off (click “stop video”) so that Zoom does not record you.*

*The chat box is always open for discussion and questions to the entire class. You may also send messages privately to the instructor. Please note that Zoom saves all chat transcripts.*
:::

::: {.absolute bottom=50 left=260 width=1500}

Slides found at: <https://maryryan.github.io/PHS-651-slides/PHS-651-8/slides-8>

:::

::: {.absolute bottom=0 left=100 width=150}
```{r qr code, echo=F, fig.height=2, fig.width=2}
plot(qr_code("https://maryryan.github.io/PHS-651-slides/PHS-651-8/slides-8"))
```
:::

---

## Recap: Non-longitudinal GEEs

Recall: a GEE has 2 main components

1. Marginal expectation of the outcome ("the mean model"): $E[Y_{ij}|X_{ij}]=\mu_{ij}$

2.1 The marginal variance of the outcome: $Var[Y_{ij}|\vec{X}_{ij}] = \varphi v(\mu_{ij})$

2.2 The within-cluster association of the outcome ("correlation structure")

We can combine 2.1 and 2.2 to create the working covariance matrix $V_i$

---

## Longitudinal GEEs

We can easily extend this framework to longitudinal data

[How would we modify each of the components?]{.alert}

1. Marginal expectation of the outcome

<br>
<br>
<br>

2.1 The marginal variance of the outcome

<br>
<br>
<br>

2.2 The within-cluster association of the outcome ("correlation structure")

<br>
<br>
<br>

---

## Longitudinal GEEs

We can easily extend this framework to longitudinal data

1. Marginal expectation of the outcome

   - Simply add time (and possibly exposure-by-time interactions) to the mean model

$$g(E[Y_{ij}]) = \beta_0 + \beta_1U_{i0} + \beta_2(\text{Time}_{ij}) + \beta_3(U_{i0} \times \text{Time}_{ij})$$

. . .

2.1 The marginal variance of the outcome

   - Will probably stay the same, unless we want different variances at different time ppints

$$Var[Y_{ij}|\vec{X}_{ij}] = \varphi v(\mu_{ij})$$

. . .

2.2 The within-cluster association of the outcome ("correlation structure")

   - Can use some of the more complex correlation structures we talked about in Lecture 7!

---

## Example: 

---

## GLMMs and longitudinal data

Extending GEEs to longitudinal data was fairly straightforward

- Few distributional assumptions means subbing in new mean model and correlation structure is easy

Due to its distributional assumptions, doing the same extension for GLMMs is slightly more involved...

---

## Recap: Non-longitudinal GLMMs

Recall the random effects model we used for non-longitudinal clustered data:
$$g(\vec{Y}_i) = \boldsymbol{X}_i\vec{\beta} + \vec{Z}_ib_{0i}+\vec{\epsilon}_i$$

- Where we assumed that each cluster had it's own cluster-specific mean ($\beta_0 + b_{0i}$) that varied by some $b_{0i}$ around the overall sample mean $\beta_0$

- We called $b_{i0}$ the [random intercept]{.alert}

. . .

The random intercept induced an exchangeable covariance matrix:
$$\begin{align*}Var[\vec{Y}_i] &= [\text{cluster-to-cluster variation}] + [\text{within-cluster member-to-member variation}]\\
&=\begin{bmatrix}
\sigma^2_b & \sigma^2_b & \dots & \sigma^2_b\\
\sigma^2_b & \ddots & \dots & \sigma^2_b\\
\vdots & \dots & \ddots & \vdots\\
\sigma^2_b & \dots & \sigma^2_b & \sigma^2_b
\end{bmatrix} + \begin{bmatrix}
\sigma^2_\epsilon & 0 & \dots & 0\\
0 & \ddots & \dots & 0\\
\vdots & \dots & \ddots & \vdots\\
0& \dots & 0 & \sigma^2_\epsilon
\end{bmatrix}=\begin{bmatrix}
\sigma^2_b + \sigma^2_\epsilon & \sigma^2_b & \dots & \sigma^2_b\\
\sigma^2_b & \ddots & \dots & \sigma^2_b\\
\vdots & \dots & \ddots & \vdots\\
\sigma^2_b & \dots & \sigma^2_b & \sigma^2_b + \sigma^2_\epsilon
\end{bmatrix}\end{align*}$$

---

## Longitudinal GLMMs

Extending the random effects model longitudinal data:
$$g(Y_{ij}) = \beta_0 + \beta_1U_{i0} + \beta_2(\text{Time}_{ij}) + b_{0i}Z_i+\epsilon_{ij}$$

what is the interpretation of:

- $\beta_0$:

- $\beta_0 + b_{0i}$:

- $\beta_1$:

- $\beta_2$:

---

## Longitudinal GLMMs

Extending the random effects model longitudinal data:
$$g(Y_{ij}) = \beta_0 + \beta_1U_{i0} + \beta_2(\text{Time}_{ij}) + b_{0i}Z_i+\epsilon_{ij}$$

The random intercept still induces an exchangeable covariance matrix:
$$Var[\vec{Y}_i] =\begin{bmatrix}
\sigma^2_b + \sigma^2_\epsilon & \sigma^2_b & \dots & \sigma^2_b\\
\sigma^2_b & \ddots & \dots & \sigma^2_b\\
\vdots & \dots & \ddots & \vdots\\
\sigma^2_b & \dots & \sigma^2_b & \sigma^2_b + \sigma^2_\epsilon
\end{bmatrix}$$

This assumes that every member of cluster $i$ has the same relationship to one another (same correlation)

. . .

- In longitudinal data, though, cluster $i$ is a single person and the "members" of the cluster are observations collected at separate time points

- An observation collected at time 1 may relate to observations at times 2 and 3 differently

---

## Longitudinal GLMMs

Extending the random effects model longitudinal data:
$$g(Y_{ij}) = \beta_0 + \beta_1U_{i0} + \beta_2(\text{Time}_{ij}) + b_{0i}Z_i+\epsilon_{ij}$$

Additionally, inclusion of only [random intercepts]{.alert} assumes that, though everyone's may randomly vary around some global baseline, everyone has the [same outcome trajectory]{.alert} over time

:::: {.columns}
::: {.column width="50%"}
![](rand-intercept.png){width="80%"}
:::

::: {.column width="50%"}
- Different issue from exposure-by-time interaction

[One solution would be to allow for each cluster to have [variation in its slope]{.alert} as well]{.fragment}

[- Random slopes and intercepts!]{.alert .fragment}
:::
::::

---

## Random slope and intercept model

Consider a model with intercepts and slopes that vary randomly among individuals:

$$g(Y_{ij}) = \beta_0 + t_{ij}\beta_1 + U_{i0}\beta_2 + Z_i0b_{i0} + t_{ij}b_{i1} + e_{ij}$$

- This model suggests that individuals vary not only in their baseline level of response (when $t_{i1} = 0$), but also in terms of their changes in the response over time

![](rand-slope.png){width="40%"}

---

## Random slope and intercept model

Consider a model with intercepts and slopes that vary randomly among individuals:

$$g(Y_{ij}) = \beta_0 + t_{ij}\beta_1 + U_{i0}\beta_2 + Z_i0b_{i0} + t_{ij}b_{i1} + e_{ij}$$

Here we assume:

$$b_{i0} \sim N(0, \sigma^2_{b0})$$
$$b_{i1} \sim N(0, \sigma^2_{b1})$$
$$\epsilon_{ij} \sim N(0, \sigma^2_\epsilon)$$

. . .

We also assume:
$$Cov[b_{i0}, b_{i1}] = \sigma_{b0,b1}$$

- The random slopes and intercepts aren't independent!

---

## Variance/covariance of random effects

In general, any component of $\beta$ can be allowed to vary randomly by simply including corresponding covariate in $Z_{ij}$

- The vector of random effects, $\vec{b}_i$, are assumed to have a multivariate normal distribution with mean zero and covariance matrix $\boldsymbol{G}$

$$\vec{b}_i \sim MVN(\vec{0}, \boldsymbol{G})$$

For example, in the random intercepts and slopes model considered earlier
$$\begin{bmatrix}
\sigma^2_{b0} & \sigma_{b0,b1}\\
\sigma_{b0,b1} &  \sigma^2_{b1}\end{bmatrix}$$

---

## Variance/covariance of the outcome

What does this mean for the covariance matrix of the outcome?

. . .

If we assume the within-individual errors are independent, then the variance of a single outcome measure is:
$$\begin{align*}Var[Y_{ij}] &= Var[\boldsymbol{X}_i\vec{\beta} + \boldsymbol{Z}_i\vec{b}_{i}+\epsilon_{ij}]\\
&= Var[\boldsymbol{Z}_i \vec{b}_{i}+\epsilon_{ij}]\\
&= Var[\vec{Z}_{1i} b_{i0} + t_{ij} b_{i1} +\epsilon_{ij}]\\
&= Var[\vec{Z}_{1i} b_{i0}] + Var[t_{ij} b_{i1}] + 2Cov[\vec{Z}_{1i} b_{i0}, t_{ij} b_{i1}]+Var[\epsilon_{ij}]\\
&= \sigma^2_{b1} + t^2_{ij}\sigma^2_{b1}+ 2t_{ij}\sigma_{b0,b1} + \sigma^2_{\epsilon}\end{align*}$$

---

## Variance/covariance of the outcome

What does this mean for the covariance matrix of the outcome?

If we assume the within-individual errors are independent, then the variance of a single outcome measure is:
$$Var[Y_{ij}] = \sigma^2_{b1} + t^2_{ij}\sigma^2_{b1}+ 2t_{ij}\sigma_{b0,b1} + \sigma^2_{\epsilon}$$

. . .

And the covariance between 2 outcome measures in the same cluster is:
$$\begin{align*}Cov[Y_{ij}, Y_{ik}] &= Cov[\boldsymbol{X}_i\vec{\beta} + \boldsymbol{Z}_i\vec{b}_{i}+\epsilon_{ij}, \boldsymbol{X}_i\vec{\beta} + \boldsymbol{Z}_i\vec{b}_{i}+\epsilon_{ik}]\\
&= Cov[\vec{Z}_{1i}b_{i0} +t_{ij}b_{i1}+\epsilon_{ij}, \vec{Z}_{1i}b_{i0}+t_{ik}b_{i1}+\epsilon_{ik}]\\
&= Cov[\vec{Z}_{1i}b_{i0}, \vec{Z}_{1i}b_{i0}] + Cov[\vec{Z}_{1i}b_{i0}, t_{ik}b_{01}] + Cov[\vec{Z}_{i1}b_{i0}, \epsilon_{ik}] + Cov[t_{ij}b_{i1}, \vec{Z}_{1i}b_{i0}]\\
&~~~~~~+ Cov[t_{ij}b_{i1}, t_{ik}b_{i1}] + Cov[t_{ij}b_{i1}, \epsilon_{ik}] + Cov[\epsilon_{ij}, \vec{Z}_{1i}b_{i0}] + Cov[\epsilon_{ij}, t_{ik}b_{i1}] + Cov[\epsilon_{ij}, \epsilon_{ik}]\\
&= \sigma^2_{b1} + t_{ik}\sigma_{b0,b1} + 0 + t_{ij}\sigma_{b0,b1} + t_{ij}t_{ik}\sigma^2_2 + 0 + 0 + 0 + 0\\
&= \sigma^2_{b1} + (t_{ij} + t_{ik})\sigma_{b0,b1} + t_{ij}t_{ik}\sigma^2_{b1}\end{align*}$$

---

## Variance/covariance of the outcome

What does this mean for the covariance matrix of the outcome?

If we assume the within-individual errors are independent, then the variance of a single outcome measure is:
$$Var[Y_{ij}] = \sigma^2_{b1} + t^2_{ij}\sigma^2_{b1}+ 2t_{ij}\sigma_{b0,b1} + \sigma^2_{\epsilon}$$

And the covariance between 2 outcome measures in the same cluster is:
$$Cov[Y_{ij}, Y_{ik}] = \sigma^2_{b1} + (t_{ij} + t_{ik})\sigma_{b0,b1} + t_{ij}t_{ik}\sigma^2_{b1}$$

. . .

[The variance and covariance are both functions of time!]{.alert}

- If $\sigma_{b0,b1}=0$, then $Var[Y_{ij}]$ increases with time

---



