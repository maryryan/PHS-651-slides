---
format: 
   revealjs:
      theme: ["../theme/q-theme.scss"]
      slide-number: c/t
      logo: POPUHEALSMPH_color-flush.png
      code-copy: true
      center-title-slide: false
      code-link: true
      code-overflow: wrap
      highlight-style: a11y
      height: 1080
      width: 1920
      chalkboard: true
      from: markdown+emoji
      fragment: true
      auto-stretch: false
execute: 
   eval: true
   echo: true
editor: 
  markdown: 
    wrap: 72
---

```{r load libraries, echo=F}
library(tidyverse)
library(ggdag)
library(dagitty)
library(gridExtra)
library(qrcode)
library(MASS)
library(gee)
```

<h1>Lecture 5.1: Modeling correlated count data</h1>

<h2>PHS 651: Advanced regression methods</h2>

<hr>

<h3>Mary Ryan Baumann, PhD</h3>

<h3>October 8, 2024</h3>

<br>

::: {style="font-size: 75%;"}
**Recording disclosure**

*This class is being conducted in person, as well as over [Zoom]{.alert}. As the instructor, I will be [recording]{.alert} this session. I have disabled the recording feature for others so that no one else will be able to record this session. I will be posting this session to the course’s website.*

*If you have privacy concerns and do not wish to appear in the recording, you may turn video off (click “stop video”) so that Zoom does not record you.*

*The chat box is always open for discussion and questions to the entire class. You may also send messages privately to the instructor. Please note that Zoom saves all chat transcripts.*
:::

::: {.absolute bottom=50 left=260 width=1500}

Slides found at: <https://maryryan.github.io/PHS-651-slides/PHS-651-4/slides-4>

:::

::: {.absolute bottom=0 left=100 width=150}
```{r qr code, echo=F, fig.height=2, fig.width=2}
plot(qr_code("https://maryryan.github.io/PHS-651-slides/PHS-651-5/slides-5"))
```
:::

---

## 552 review: Count data regression

---

## Count outcomes and GLMMs (poisson)

We've focused a lot on binary outcomes up until now, but count data (Poisson-distributed) can also be modeled using a GLMM

-   If we have $\vec{Y}_i$ that is distributed Poisson with event rate $\lambda_{ij}$ (# events per unit of time)

    -   Thus the mean for $Y_{ij}$, $E[Y_{ij}|\boldsymbol{X}_i, b_{0i}] = \mu_{ij}$, is the average count for a given unit of time, which is $\mu_{ij}= \lambda_{ij}T_{ij}$

-   We want to know what effect exposure $U_{ij}$ has on $\vec{Y}_i$

[What would our model look like?]{.alert}

$$\text{log}(Y_{ij}) = \beta_0 + U_{ij}\beta_1 + Z_i b_{0i} + \log(T_{ij})$$

where $b_{0i} \sim N(0, \sigma^2_b)$

. . .

[Note the lack of $\epsilon_{ij}$!]{.alert}

-   This is because the Poisson distribution assumes $E[Y_{ij}|\boldsymbol{X}_i, b_{0i}] = Var[Y_{ij}|\boldsymbol{X}_i, b_{0i}] = \mu_{ij}$

    -   However, this assumption is rarely true in real life (health) applications

    -   Often, $Var[Y|\boldsymbol{X}_i, b_{0i}]>E[Y|\boldsymbol{X}_i, b_{0i}]$, known as [over-dispersion]{.alert}

```{r glmm poisson, eval=F, echo=F}
library(MASS)
glmmPQL( y ~ u,
         random = ~ 1 | cluster, family = quasipoisson(link="log"),
         data=data)
```

------------------------------------------------------------------------

## Count outcomes and GLMMs (negative binomial)

When count data are over-dispersed, we can use a [negative-binomial]{.alert} regression model

$$\text{log}(Y_{ij}) = \beta_0 + U_{ij}\beta_1 + Z_i b_{0i} + \log(T_{ij}) + \epsilon_{ij}$$

where $b_{0i}\sim N(0,\sigma^2_b)$ and $\exp(\epsilon_{ij}) \sim \text{Gamma}(1,\theta)$

. . .

-   This means $Var(Y_{ij}|\boldsymbol{X}_i, b_{0i}) = E[Y_{ij}|\boldsymbol{X}_i, b_{0i}] + \theta\left(E[Y_{ij}|\boldsymbol{X}_i, b_{0i}]\right)^2 = \mu_{ij} + \theta \mu_{ij}^2$

-   Our covariance structure then looks like

$$\begin{bmatrix}
\sigma^2_b + \mu_{ij} + \theta \mu_{ij}^2 & \sigma^2_b & \dots & \sigma^2_b\\
\sigma^2_b & \ddots & \dots & \sigma^2_b\\
\vdots & \dots & \ddots & \vdots\\
\sigma^2_b & \dots & \sigma^2_b & \sigma^2_b + \mu_{ij} + \theta \mu_{ij}^2
\end{bmatrix}$$

```{r glmm neg bin, eval=F, echo=F}
glmmPQL( y ~ u,
         random = ~ 1 | cluster, family = negative.binomial(theta = 1),
         data=data)
```

------------------------------------------------------------------------

## Example: murders and income

Let's say we want to see whether the real per capita personal income of a county impacts its number of murders

-   Data from 1980

-   Assume clustering by state

```{r murder cleaning, echo=F}
library(wooldridge)

murder <- countymurders %>% 
   dplyr::filter(year==1980)
```

------------------------------------------------------------------------

## Example: murders and income

Let's get an idea of our data...

```{r murder table 1}
murder %>% 
   group_by(statefips) %>% 
   summarize(n=n(), mean_murders=mean(murders, na.rm=T), mean_capita = mean(rpcpersinc))
```

------------------------------------------------------------------------

## Example: murders and income

First our Poisson mixed effects model:

$$\text{log}(\text{number of murders}_{ij}) = \beta_0 + \beta_1(\text{per capita personal income}_{ij}) + b_{0i}$$

-   All data is on the per-year scale so $T_{ij}=1$, and $\log(T_{ij})=0$, so no need to add the time offset term

```{r murder glmm}
murder_glmm <- glmmPQL( murders ~ rpcpersinc,
         random = ~ 1 | statefips, family = quasipoisson(link="log"), data = murder, 
         verbose = F )
summary( murder_glmm )$tTable

```

Poisson GLMM results:

-   Poisson $e^{\beta_1}$: `r round(exp(murder_glmm$coefficients$fixed[2]), 4)`

    -   95% CI: (`r round(exp(murder_glmm$coefficients$fixed[2] - summary(murder_glmm)$tTable[2,2]*pnorm(0.975)), 4)`, `r round(exp(murder_glmm$coefficients$fixed[2] + summary(murder_glmm)$tTable[2,2]*pnorm(0.975)), 4)`)

------------------------------------------------------------------------

## Example: murders and income

Now our negative binomial mixed effects model:

$$\text{log}(\text{number of murders}_{ij}) = \beta_0 + \beta_1(\text{per capita personal income}_{ij}) + b_{0i} + \epsilon_{ij}$$

```{r murder glmmnb}
# find theta #
murder_theta <- glm.nb(murders ~ rpcpersinc, data=murder)$call$init.theta

# fit model #
murder_glmmnb <- glmmPQL( murders ~ rpcpersinc,
         random = ~ 1 | statefips, family = negative.binomial(theta = murder_theta), data = murder, 
         verbose = F )
summary( murder_glmmnb )$tTable

```

Negative Binomial GLMM results:

-   NB $e^{\beta_1}$: `r round(exp(murder_glmmnb$coefficients$fixed[2]), 4)`

    -   95% CI: (`r round(exp(murder_glmmnb$coefficients$fixed[2] - summary(murder_glmmnb)$tTable[2,2]*pnorm(0.975)), 4)`, `r round(exp(murder_glmmnb$coefficients$fixed[2] + summary(murder_glmmnb)$tTable[2,2]*pnorm(0.975)), 4)`)

------------------------------------------------------------------------

## GEEs and count data

GEEs are particularly useful when it comes to modeling [count outcomes]{.alert}

-   This is because GEEs empirically estimate the variances rather than using distributional (Poisson) assumptions

-   Result: GEEs automatically account for over-dispersion

------------------------------------------------------------------------

## GLMMs vs GEEs: murder

Let's see how GLMMs and GEEs compare with count data

-   Recall our county murder example

-   Want to see whether the real per capita personal income of a county impacts the number of murders

------------------------------------------------------------------------

## GLMMs vs GEEs: murder

First our LME model:

$$\text{log}(\text{number of murders}_{ij}) = \beta_0 + \beta_1(\text{per capita personal income}_{ij}) + b_{0i} + \epsilon_{ij}$$

```{r murder glmm2}
murder_glmm <- glmmPQL( murders ~ rpcpersinc,
         random = ~ 1 | statefips, family = poisson, data = murder, 
         verbose = F )
summary( murder_glmm )$tTable

```

Logistic GLMM results:

-   GLMM $e^{\beta_1}$: `r round(exp(murder_glmm$coefficients$fixed[2]), 4)`

    -   95% CI: (`r round(exp(murder_glmm$coefficients$fixed[2] - summary(murder_glmm)$tTable[2,2]*pnorm(0.975)), 4)`, `r round(exp(murder_glmm$coefficients$fixed[2] + summary(murder_glmm)$tTable[2,2]*pnorm(0.975)), 4)`)

------------------------------------------------------------------------

## GLMMs vs GEEs: murder

Now let's fit a GEE:

```{r murder gee}
# run an LME with random intercepts for county #
murder_gee <- gee( murders ~ rpcpersinc,
                  id=statefips, data=murder,
                  family=poisson,
                  corstr="exchangeable" )
summary( murder_gee )$coef
```

-   GEE $e^{\beta_1}$: `r round(exp(summary(murder_gee)$coef[2,1]),4)`

    -   95% CI: (`r round(exp(summary(murder_gee)$coef[2,1] - summary(murder_gee)$coef[2,2]*pnorm(0.975)), 4)`, `r round(exp(summary(murder_gee)$coef[2,1] + summary(murder_gee)$coef[2,2]*pnorm(0.975)), 4)`)
